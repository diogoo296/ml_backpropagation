# ML Backpropagation
This is a Backpropagation implementation for a Machine Learning course assignment.

# About this project
This project can be summarized as an adaptation of Michael Niesen (see Reference) code to a specific implementation of backpropagation using gradient descent, SGD and mini batch. The loss function to be minimized was the binary cross entropy.

# Reference
Michael Nielsen - Neural Networks and Deep Learning - Chapter 3

* [Link to webpage](http://neuralnetworksanddeeplearning.com/chap3.html)
* [Link to Github code](https://github.com/mnielsen/neural-networks-and-deep-learning/blob/master/src/network2.py)
