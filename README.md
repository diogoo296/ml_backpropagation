# ML Backpropagation
This is a Backpropagation implementation for a Machine Learning course assignment.

# About this project
This project can be summarized as an adaptation of Michael Niesen (see Reference) code to a specific implementation of backpropagation using gradient descent, SGD and mini batch. The loss function to be minimized was the binary cross entropy.

#Reference
Michael Nielsen - Neural Networks and Deep Learning - Chapter 3
[Link to webpage](http://neuralnetworksanddeeplearning.com/chap3.html)
[Link to Github code](https://github.com/mnielsen/neural-networks-and-deep-learning/blob/master/src/network2.py)
